# Cohere Labs Staff Discussion - Timestamped Transcript

**Video:** https://www.youtube.com/watch?v=EqbutUc5a_Q
**Duration:** 10 minutes
**Extracted:** August 11, 2025

## Full Transcript with Timestamps

[00:05] Hello everyone. I'm Sarah Hooker. I lead
[00:08] Coher's research arm. Uh today we're
[00:11] talking about the scholars program and
[00:13] which is our bet on finding the best
[00:16] engineers around the world and giving
[00:18] them that first door into AI top tier
[00:22] research at a frontier lab. Um but to
[00:25] start I kind of want to um take a wider
[00:28] look. So um Ahmed Marzia like you've
[00:32] been both involved in art scholars
[00:34] program you look have to look at
[00:35] hundreds and hundreds of applications
[00:38] uh how do what do you think makes a you
[00:41] know a meaningful application like what
[00:43] should people think about as they think
[00:44] about applying to our lab?
[00:46] Uh yeah I think our scholar program is
[00:48] very unique in the sense that we are
[00:50] looking for people with very little
[00:52] research background because we want to
[00:53] help them get into research. So uh it's
[00:57] it makes it a little bit difficult to uh
[01:00] evaluate people because they haven't
[01:02] done research. uh but uh what I think
[01:05] makes a really good scholar is someone
[01:08] who is curious and passionate and cares
[01:12] about learning and uh because this is a
[01:15] great learning opportunity both about
[01:17] the problem itself that they will be
[01:19] working on but also just working with
[01:21] the mentors uh at coher and uh learning
[01:25] about how research is done from
[01:26] everyone. So uh my uh I guess like what
[01:31] I I'm always looking for is someone who
[01:33] is uh very uh open and curious and wants
[01:37] to learn. So that's uh very important.
[01:39] And Ahmed, so you're a very experienced
[01:42] researcher. Who opened that first door
[01:44] for you? Who first got you gave you your
[01:46] first shot at AI research?
[01:48] Um, for AI research, my I think bachelor
[01:51] uh supervisor uh let me say that that
[01:54] way. But uh I think beyond not only AI
[01:57] research but I think this is about
[01:58] research like research motivation to
[02:00] explore something. Mhm.
[02:02] That is definitely my father because he
[02:04] always pushed me to okay if you are
[02:06] doing something do for the depth of it
[02:08] you know I think this is the gist of the
[02:11] being research actually how we also look
[02:13] at the scholar program in my opinion is
[02:15] really like that if someone is really
[02:17] passionate about exploring something
[02:19] this is the core skill
[02:22] yeah and this is a good time this is a
[02:23] good moment to also ask so what what
[02:27] makes for a successful researcher like
[02:28] when you look at uh your colleagues like
[02:31] what are traits that you think and not
[02:33] your media colleagues it could be the
[02:34] wider field but like what traits do you
[02:36] think uh make for success in research
[02:39] and John you are one of our scholars and
[02:41] you've joined as a research engineer um
[02:43] what do you think makes for um success
[02:46] in this field
[02:47] yeah I think there there are a couple
[02:48] things that really stand out when I look
[02:50] at great researchers um I think one is
[02:54] being able to ask the right questions
[02:56] like what Marzia um was talking about
[02:59] earlier about curiosity being really
[03:00] important and um asking questions that
[03:03] challenge the status quo and
[03:05] conventional ways of thinking are really
[03:07] critical to getting novel ideas um off
[03:10] the ground and spurring new research
[03:13] innovation. Um, and I think the second
[03:15] thing is just being super collaborative
[03:17] and having the ability to work with
[03:20] people from all sorts of different
[03:22] backgrounds and synthesizing their
[03:23] different points of view to be able to
[03:25] coordinate and um, work towards a
[03:28] research agenda I think is really
[03:29] critical to uh, making a lot of the
[03:31] breakthroughs.
[03:32] Yeah, I agree. We're kind of in an era
[03:34] of where there's a huge amount of
[03:36] compute needed for the type of work we
[03:37] do at our lab as well as it's massive
[03:40] infrastructure bets and so coordination
[03:42] being able to have discipline in your u
[03:45] methodology but also clear hypotheses
[03:47] like failing fast iterating learning I
[03:49] think are really important. Um, so what
[03:51] was one thing that was a surprise to
[03:54] you, John, when you chose to kind of
[03:56] join the program? Uh, and maybe one
[03:59] thing that you think people uh don't
[04:01] know about the scholars program.
[04:03] I think coming in what I expected was
[04:04] that, you know, the people who were
[04:06] working directly on my project would be
[04:09] u my closest collaborators and it mostly
[04:10] be talking with them. But I think
[04:12] something really uh pleasantly
[04:13] surprising was that I think everyone in
[04:16] the entire lab was really invested in my
[04:19] success and had a lot of ideas and
[04:21] thoughts to contribute to my project and
[04:23] my research even if they weren't
[04:25] directly working on the project. And
[04:27] that kind of feedback and insight from
[04:29] people you know across the entire team
[04:31] that are working in your project and
[04:33] also have a more outside perspective I
[04:35] think was really helpful in I guess
[04:37] driving um the research direction and
[04:40] getting as much perspective and ideas as
[04:41] possible
[04:42] and what is your research tell us about
[04:44] it and also why is it very critical to
[04:46] this particular era of AI. So when I
[04:49] joined as a research scholar um a year
[04:51] ago uh I joined to work on um getting uh
[04:56] reinforce and learning from human
[04:57] feedback or preference training which is
[04:59] become a really standard critical piece
[05:00] of training state-of-the-art foundation
[05:02] models and making it work in uh
[05:04] multilingual settings. So when we look
[05:07] widely at the field currently uh most of
[05:10] the works in getting our models to be
[05:12] more aligned to human preferences have
[05:14] been really mostly exclusively focused
[05:16] on high resource languages like English
[05:19] and as a result what we find is that
[05:21] many of these models perform not very
[05:24] well and um often means that you know
[05:27] people who don't uh speak English or
[05:29] these high resource languages are often
[05:30] excluded from access to these
[05:32] technologies which are becoming
[05:33] increasingly important. So I was working
[05:36] on trying to bring these
[05:37] state-of-the-art alignment techniques to
[05:40] uh multilingual models and making them
[05:42] effective for improving the multilingual
[05:44] performance of these models across a
[05:46] wide variety of languages.
[05:47] Yeah, I think alignment is uh and this
[05:49] steering of models because we're kind of
[05:51] steering the models to what we think um
[05:53] humans care about. This is really uh at
[05:57] the heart of making that much more
[06:00] realistic for the complexity of the
[06:02] world because when we steer
[06:03] traditionally it's been towards I guess
[06:06] a single global preference and we all
[06:08] know that's not true and this first gets
[06:10] us thinking about multi-objective
[06:12] there's many different preferences and
[06:14] we have to create models which can adapt
[06:16] and understand and balance different
[06:19] objectives so this is really profound um
[06:21] I want to open it up I want to ask so
[06:24] you know um Marsia Ahmed, what's one
[06:26] piece of advice that you would give to
[06:28] your younger research self and that you
[06:30] would give you know to scholars who are
[06:32] just starting out?
[06:33] I think I guess for me
[06:35] no pressure.
[06:35] Yeah, it it is a lesson that I learned
[06:39] over time and uh I usually now say that
[06:43] to if I'm mentoring someone but I would
[06:45] have also mentored my younger self and I
[06:47] would say that is just how to view
[06:51] failures as a point of learning. Uh it
[06:54] might be a little bit like a cliche but
[06:57] really uh the the best learning lessons
[07:00] happen when failures happen and that can
[07:02] be in your uh in in the actual
[07:05] experiment that you're running the
[07:06] hypothesis that you had that you are
[07:08] validating uh but also in general in in
[07:11] life like what you think might be
[07:13] something you want at one point and you
[07:15] don't get uh learning from that and get
[07:19] better and move. That's
[07:21] perseverance is crucial ingredient of um
[07:24] just really developing anything that is
[07:26] unknown. But it's um I often say one of
[07:29] the core ingredients is just being the
[07:31] last one working on the problem. It's a
[07:33] balance but I do think this is a core
[07:36] component of even uh really being
[07:38] successful as you're just starting out
[07:40] in anything. You have to build a craft
[07:41] which often just involves repetition to
[07:43] begin with. Um, and almost everyone who
[07:46] ends up at the frontier of AI who's very
[07:49] accomplished, they've all developed the
[07:52] craft. And then what happens after that
[07:53] is the magic of having like a research
[07:55] taste and a perspective. But to get
[07:57] there, you first just have to build that
[07:59] craft. It's kind of like any type of um
[08:03] really uh specialization or being an
[08:05] expert in everything. There's a lot of
[08:07] repetition and perseverance initially.
[08:09] Um, I want to ask a question. Maybe I'll
[08:11] switch it on. So, so I I think this is
[08:14] one aspect that I'm quite proud about is
[08:16] that we scholars one of the key goals is
[08:18] to still publish. We've seen this
[08:19] closing down of publishing in industry
[08:21] labs. I guess there's why is that trend
[08:24] happening and you know why is it so
[08:26] important that we still have programs
[08:27] that publish and release work.
[08:29] Uh I think this this trend happens
[08:31] because of the the reality of AI now the
[08:34] fast adaption also comes with the
[08:36] financial outcome.
[08:37] Yeah. And like there's a huge
[08:39] competition because of the same reason
[08:41] because of the financial outcome that
[08:44] leads AI labs to publish less. The one
[08:47] thing that is sort of missing in this uh
[08:49] formulation is like when we publish less
[08:52] then this adaption and this pace will
[08:54] eventually slow down. So to keep this
[08:56] pace same or even go beyond we have to
[08:59] do research we have to do open science
[09:01] and we have to publish. That's why I
[09:03] feel super lucky that as a lab we really
[09:06] publish not only publish with the stuff
[09:09] but also really open up entry points for
[09:11] junior researcher new superstars. I
[09:13] think this is because this really kind
[09:16] of two-way thing as we publish more we
[09:19] have this open up entry points when we
[09:22] have more entry points when we lots of
[09:23] new junior researchers then we actually
[09:26] publish better. So I think that's uh
[09:29] yeah that's what I think about that.
[09:31] Yeah. So if you come to our events,
[09:32] we'll actually share what we're working
[09:34] on. Um but this was very nice, amazing.
[09:37] I think the scholars program is one of
[09:39] the pillars of how we innovate and how
[09:41] we work on the next generation models.
[09:43] So thanks everyone for sharing your
[09:45] perspective. So Ahmed and Moisia and
[09:48] John often often mentoring the scholars
[09:50] projects and John joined us from the
[09:52] scholars program. So it's really nice to
[09:54] have your perspective as people think
[09:55] about this.
